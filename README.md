 Ten-animales-classifier
 =================================

# Introduction: 

This  Python notebook provid a comprehensive image classification project using TensorFlow. It covers data organization, Convolutional Neural Network (CNN) model construction, dataset loading, model training with callbacks, feature extraction from a pre-trained VGG16 model, fine-tuning, and evaluation of the fine-tuned model's performance on a test dataset. This script demonstrates a holistic workflow for image classification.


## Import necessary libraries and modules

- `os`: This module allows interaction with the operating system, enabling file and directory operations.
- `shutil`: The `shutil` module is used for high-level file operations, such as copying and moving files and directories.
- `train_test_split` from `sklearn.model_selection`: This function is essential for splitting datasets into training and testing sets, a common task in machine learning.
- `random`: The `random` module provides functions for generating random numbers and performing randomization, which can be useful for various tasks, including data shuffling.
- `matplotlib.pyplot as plt`: `matplotlib` is a popular library for creating data visualizations. `pyplot` is a module within `matplotlib` that provides a simple and interactive way to create plots and charts.
- `matplotlib.image as mpimg`: The `mpimg` module is used for working with images, including loading and displaying them.
- `tensorflow as tf`: TensorFlow is a deep learning framework, and it is imported as `tf`. It is used for building and training machine learning models.
- `keras` from `tensorflow`: Keras is a high-level neural networks API that runs on top of TensorFlow. It is widely used for defining and training deep learning models.
- `layers, regularizers` from `tensorflow.keras`: These are submodules of the Keras library and provide tools for building and configuring neural network layers and applying regularization techniques to models.
- `numpy as np`: NumPy is a fundamental library for numerical operations in Python. It provides support for arrays, matrices, and various mathematical operations, which are essential for data processing in machine learning.

These imports set the stage for various operations related to data manipulation, model construction, and visualization in the subsequent code.

## Data Directory Setup

- `input_data_dir`: Specifies the directory where the original read-only dataset is located, in this case, "/kaggle/input/animals10/raw-img".
- `output_dir`: Defines the directory where the working dataset will be created, which is "/kaggle/working/dataset".

## Create Subdirectories

- `train_dir`, `validation_dir`, and `test_dir` are defined as subdirectories within the `output_dir`. These will be used to store the training, validation, and test data, respectively.
- `os.makedirs` is used to create these subdirectories if they don't already exist, setting `exist_ok=True`.

## Split Data into Sets

- `class_folders` is a list of class folders (e.g., categories of animals) within the input data directory.
- `train_classes`, `validation_classes`, and `test_classes` are generated by splitting the class folders into training, validation, and testing sets using `train_test_split` from scikit-learn.

## Copy Files

- `copy_files` is a custom function that copies a specified number of files from the source directory to the destination directory. It selects files randomly.
- The function calculates the number of files to copy based on the desired number of files per class, ensuring it doesn't exceed the number of available files.
- For each class folder, files are copied to the corresponding subdirectories in the training, validation, and test sets, ensuring that the subdirectories exist.

## Organize Data

- The code organizes the data by creating subdirectories for each class in the training, validation, and test sets.
- It ensures that the necessary subdirectories are created for each class.
- Files are then copied from the original class directories to the appropriate subdirectories in the train, validation, and test sets.

## Summary

- Finally, the code prints the number of files in each set, providing an overview of how many images are available for each class within the training, validation, and test sets.

